# ðŸš€ Pre-Computed Matching Setup Guide

## âš¡ Performance Improvement: **120 seconds â†’ <100ms** (1200x faster!)

---

## ðŸ“‹ Overview

This guide will help you set up **pre-computed job-candidate matching** to eliminate the timeout issues and provide instant results.

### **Current Problem:**
- âŒ Matching takes 120+ seconds (times out)
- âŒ Processes 433 CVs in real-time
- âŒ Loads semantic AI models on every request
- âŒ Terrible user experience

### **Solution:**
- âœ… Pre-compute all matches once (background job)
- âœ… Store results in database table
- âœ… API reads from cache (<100ms response)
- âœ… Refresh periodically (hourly/daily)

---

## ðŸŽ¯ Quick Start (3 Steps)

### **Step 1: Create the Cache Table** (30 seconds)

```bash
cd C:\Dev\ai-job-matchingV2\backend
python precompute_matches.py --create-table
```

**Expected output:**
```
ðŸ“‹ Creating job_candidate_matches table...
âœ… Table created successfully!
```

---

### **Step 2: Compute All Matches** (30-60 minutes one-time)

```bash
python precompute_matches.py --compute --min-score 0.0
```

**What happens:**
- Loads semantic matching service (one-time)
- Processes all jobs Ã— all CVs
- Stores matches in database
- Shows progress every job

**Expected output:**
```
ðŸ¤– Initializing semantic matching service...
âœ… Service initialized in 8.2s

ðŸ“Š Fetching jobs...
âœ… Found 1,600 jobs to process

ðŸ“Š Fetching CVs...
âœ… Found 2,500 CVs to process

ðŸŽ¯ Total matches to compute: 4,000,000
â±ï¸  Estimated time: 55.6 minutes

================================================================================
ðŸŽ¯ Job 1/1,600: Accountant at Zanaco
================================================================================
   âœ… Loaded 2109 cached skill weights
   âœ… Stored 87 matches (â‰¥0%) in 12.3s
   ðŸ“Š Total stored: 87 matches
   â±ï¸  Elapsed: 0.2 min
   ðŸ• Estimated remaining: 54.8 min

...

ðŸŽ‰ COMPUTATION COMPLETE!
   âœ… Total matches stored: 142,000
   â±ï¸  Total time: 52.3 minutes
   âš¡ Average: 1.96s per job
```

**Options:**
```bash
# Only store good matches (50%+)
python precompute_matches.py --compute --min-score 0.5

# Only store excellent matches (70%+)
python precompute_matches.py --compute --min-score 0.7
```

---

### **Step 3: Update Frontend to Use Cached Endpoint**

**File:** `frontend/recruiter/src/app/dashboard/jobs/page.tsx`

**Find this line (~line 165):**
```typescript
const response = await api.get(
  `/recruiter/job/${selectedJob.job_id}/candidates`,
```

**Replace with:**
```typescript
const response = await api.get(
  `/recruiter/job/${selectedJob.job_id}/candidates/cached`,  // âš¡ NEW ENDPOINT
```

**That's it!** Now matching is instant (<100ms).

---

## ðŸ“Š Verify It Works

### **1. Check Cache Stats**

```bash
python precompute_matches.py --stats
```

**Expected output:**
```
================================================================================
ðŸ“Š MATCH CACHE STATISTICS
================================================================================
   Total matches: 142,587

   Distribution by score:
      Excellent (70%+): 3,421 (2.4%)
      Good (50-69%): 18,934 (13.3%)
      Fair (30-49%): 45,682 (32.0%)
      Low (<30%): 74,550 (52.3%)

   Cache age:
      Oldest: 2025-01-15 08:23:12
      Newest: 2025-01-15 09:15:44
```

---

### **2. Test the API**

```bash
# Get candidates for a job (instant!)
curl http://localhost:8000/api/v1/recruiter/job/ZANACO_001/candidates/cached?min_score=0.3&limit=20

# Get stats for a job
curl http://localhost:8000/api/v1/recruiter/job/ZANACO_001/candidates/stats
```

---

### **3. Test in Frontend**

1. Start backend: `python -m uvicorn app.main:app --reload`
2. Start frontend: `cd frontend/recruiter && npm run dev`
3. Login as any company (e.g., `zanaco@company.zm`)
4. Select a job
5. **Candidates should load in <1 second!** âš¡

---

## ðŸ”„ Refreshing the Cache

### **When to Refresh:**
- âœ… New CVs uploaded
- âœ… Jobs updated
- âœ… Weekly/daily maintenance

### **How to Refresh:**

```bash
# Full refresh (recompute everything)
python precompute_matches.py --compute --min-score 0.0

# Incremental refresh (TODO: implement later)
# Only recompute for new CVs or updated jobs
```

### **Automate with Cron (Linux) or Task Scheduler (Windows):**

**Linux Cron (daily at 2 AM):**
```bash
0 2 * * * cd /path/to/backend && python precompute_matches.py --compute --min-score 0.0
```

**Windows Task Scheduler:**
- Create new task
- Trigger: Daily at 2:00 AM
- Action: `python C:\Dev\ai-job-matchingV2\backend\precompute_matches.py --compute --min-score 0.0`

---

## ðŸŽ¯ API Endpoints

### **1. Get Cached Candidates** (FAST - <100ms)
```
GET /api/v1/recruiter/job/{job_id}/candidates/cached
```

**Query params:**
- `min_score` (0.0-1.0): Minimum match score
- `limit` (1-100): Max candidates to return

**Response:**
```json
{
  "job_id": "ZANACO_001",
  "job_title": "Accountant",
  "company": "Zanaco",
  "total_matches": 23,
  "min_score": 0.3,
  "candidates": [
    {
      "cv_id": "CV_0042",
      "match_score": 0.847,
      "scores": {
        "skills": 0.82,
        "experience": 1.0,
        "location": 0.7,
        "education": 1.0
      },
      "matched_skills": ["Accounting", "Financial Reporting", "Excel"],
      "missing_skills": ["SAP", "Audit"],
      "explanation": "Strong accounting background with relevant experience",
      "candidate": {
        "name": "John Banda",
        "title": "Senior Accountant",
        "location": "Lusaka, Lusaka Province",
        "email": "john.banda@example.com",
        "phone": "+260977123456",
        "experience_years": 8.5
      }
    }
  ],
  "cached": true,
  "response_time": "<100ms"
}
```

---

### **2. Get Job Stats**
```
GET /api/v1/recruiter/job/{job_id}/candidates/stats
```

**Response:**
```json
{
  "job_id": "ZANACO_001",
  "job_title": "Accountant",
  "total_candidates": 87,
  "distribution": {
    "excellent_70_plus": 5,
    "good_50_69": 18,
    "fair_30_49": 34,
    "low_under_30": 30
  },
  "highest_score": 0.891,
  "average_score": 0.423,
  "last_updated": "2025-01-15T09:15:44"
}
```

---

## ðŸ—‚ï¸ Database Schema

### **Table: `job_candidate_matches`**

```sql
CREATE TABLE job_candidate_matches (
    job_id VARCHAR NOT NULL,           -- FK to corporate_jobs
    cv_id VARCHAR NOT NULL,            -- FK to cvs
    match_score FLOAT NOT NULL,        -- 0.0 to 1.0
    skill_score FLOAT,                 -- Component scores
    experience_score FLOAT,
    location_score FLOAT,
    education_score FLOAT,
    matched_skills TEXT,               -- JSON array
    missing_skills TEXT,               -- JSON array
    match_explanation TEXT,            -- Why they match
    computed_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    PRIMARY KEY (job_id, cv_id)
);

-- Indexes for fast queries
CREATE INDEX idx_job_score ON job_candidate_matches(job_id, match_score);
CREATE INDEX idx_cv_score ON job_candidate_matches(cv_id, match_score);
CREATE INDEX idx_computed_at ON job_candidate_matches(computed_at);
```

**Estimated size:**
- 1,600 jobs Ã— 2,500 CVs = 4,000,000 potential matches
- With 30% threshold: ~120,000 stored matches
- Size per match: ~500 bytes
- **Total: ~60 MB** (very reasonable!)

---

## ðŸŽ¯ Performance Comparison

| Endpoint | Response Time | Method | Use Case |
|----------|---------------|--------|----------|
| `/candidates/cached` | **<100ms** âš¡âš¡âš¡ | Pre-computed | **Production (Recommended)** |
| `/optimized/candidates` | 2-3s âš¡âš¡ | Cached + reduced processing | Development |
| `/candidates` | 8-10s âš¡ | Real-time with cache | Legacy |
| Old endpoint | 120s+ âŒ | Real-time without cache | Deprecated |

---

## ðŸš¨ Troubleshooting

### **Problem: Table creation fails**
```bash
# Check database connection
python -c "from app.core.config import get_settings; print(get_settings().DATABASE_URL)"

# Manually create table
psql -U your_user -d job_match_db < create_table.sql
```

---

### **Problem: Computation is slow**
- âœ… **Expected:** 30-60 minutes for 1,600 jobs Ã— 2,500 CVs
- âœ… First job is slowest (loads semantic model)
- âœ… Subsequent jobs are faster (~2s each)
- âœ… Run overnight if needed

---

### **Problem: No matches found**
```bash
# Check if matches were computed
python precompute_matches.py --stats

# Try lower threshold
python precompute_matches.py --compute --min-score 0.0
```

---

### **Problem: Frontend still times out**
1. âœ… Verify you're using `/candidates/cached` endpoint
2. âœ… Check backend logs for errors
3. âœ… Test API directly: `curl http://localhost:8000/api/v1/recruiter/job/ZANACO_001/candidates/cached`

---

## ðŸŽ‰ Success Criteria

âœ… Cache table created  
âœ… Matches computed (>100,000 stored)  
âœ… API returns results in <100ms  
âœ… Frontend loads candidates instantly  
âœ… No timeout errors  

---

## ðŸ“ Next Steps

### **Phase 1 (Now):**
- âœ… Set up pre-computation
- âœ… Update frontend to use cached endpoint
- âœ… Test with real companies

### **Phase 2 (Later):**
- ðŸ”„ Incremental updates (only new CVs/jobs)
- ðŸ”„ Real-time updates on CV upload
- ðŸ”„ Scheduled refresh (cron job)
- ðŸ”„ Cache invalidation strategies

### **Phase 3 (Optional):**
- ðŸ“Š Match quality analytics
- ðŸ”” Notifications for new high-quality matches
- ðŸ“ˆ Trending candidates dashboard
- ðŸŽ¯ ML model improvements

---

## ðŸŽ¯ Summary

**Before:**
- âŒ 120+ second timeouts
- âŒ Real-time computation
- âŒ Poor user experience

**After:**
- âœ… <100ms response time
- âœ… Pre-computed matches
- âœ… Instant results
- âœ… Happy recruiters! ðŸŽ‰

**Total setup time:** 30 seconds (table) + 60 minutes (compute) + 1 minute (frontend update) = **~1 hour one-time setup**

---

**Questions?** Check the troubleshooting section or ask! ðŸš€
